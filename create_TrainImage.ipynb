{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tifffile import TiffFile\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_SIZE = 4\n",
    "MASKS = '../input/hubmap-organ-segmentation/train.csv'\n",
    "DATA = '../input/hubmap-organ-segmentation/train_images'\n",
    "OUT_TRAIN = '../input/hubmap-2022-for-Train3/train'\n",
    "OUT_MASKS = '../input/hubmap-2022-for-Train3/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rle</th>\n",
       "      <th>pixel_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10274</th>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10488</th>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10610</th>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     rle  pixel_size\n",
       "id                                                                  \n",
       "10044  1459676 77 1462675 82 1465674 87 1468673 92 14...         0.4\n",
       "10274  715707 2 718705 8 721703 11 724701 18 727692 3...         0.4\n",
       "10392  1228631 20 1231629 24 1234624 40 1237623 47 12...         0.4\n",
       "10488  3446519 15 3449517 17 3452514 20 3455510 24 34...         0.4\n",
       "10610  478925 68 481909 87 484893 105 487863 154 4908...         0.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions to convert encoding to mask and mask to encoding\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    #print(encs)\n",
    "    for m,enc in enumerate(encs):\n",
    "        \n",
    "        if isinstance(enc,np.float64) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "        break\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "df_masks = pd.read_csv(MASKS)[['id','rle','pixel_size']].set_index('id')\n",
    "df_masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the new images cannot be loaded into 16GB RAM\n",
    "# use rasterio to load image part by part\n",
    "# using a datas\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, idx, df=None):\n",
    "        with TiffFile(os.path.join(DATA,str(idx)+'.tiff')) as tif:\n",
    "            self.data = tif.asarray()\n",
    "        self.shape = self.data.shape\n",
    "        self.mask = enc2mask(df,(self.shape[1],self.shape[0])) if encs is not None else None\n",
    "        #self.new_size = (int(self.shape[0] // (PIXEL_SIZE / df['pixel_size'])), int(self.shape[1] // (PIXEL_SIZE / df['pixel_size'])))\n",
    "        self.new_size = (512, 512)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = cv2.resize(self.data,self.new_size,\n",
    "                            interpolation = cv2.INTER_AREA)\n",
    "        mask = cv2.resize(self.mask,self.new_size,\n",
    "                            interpolation = cv2.INTER_NEAREST)\n",
    "        \n",
    "        return img, mask, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bad8cbadbf7492f8352ab8a60a5df16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.82829411 0.80269686 0.8205803 ] , std: [0.15668971 0.18531429 0.17469466]\n"
     ]
    }
   ],
   "source": [
    "x_tot,x2_tot = [],[]\n",
    "for index, encs in tqdm(df_masks.iterrows(),total=len(df_masks)):\n",
    "    ds = HuBMAPDataset(index,df=encs)\n",
    "\n",
    "    im,m,idx = ds[0]\n",
    "    if idx < 0: continue\n",
    "        \n",
    "    x_tot.append((im/255.0).reshape(-1,3).mean(0))\n",
    "    x2_tot.append(((im/255.0)**2).reshape(-1,3).mean(0))\n",
    "    \n",
    "    #write data\n",
    "    train_filename = OUT_TRAIN + f'/{index}.png'\n",
    "    mask_filename = OUT_MASKS + f'/{index}.png'\n",
    "\n",
    "    cv2.imwrite(train_filename, im)\n",
    "    cv2.imwrite(mask_filename, m)\n",
    "        \n",
    "#image stats\n",
    "img_avr =  np.array(x_tot).mean(0)\n",
    "img_std =  np.sqrt(np.array(x2_tot).mean(0) - img_avr**2)\n",
    "print('mean:',img_avr, ', std:', img_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
